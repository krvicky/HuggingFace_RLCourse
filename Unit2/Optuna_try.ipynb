{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOH/PjuVisE2m/HwMnt0JWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krvicky/HuggingFace_RLCourse/blob/main/Unit2/Optuna_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium --quiet\n",
        "!pip install optuna --quiet\n",
        "!pip install stable_baselines3 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UffW_DbYvIqS",
        "outputId": "a59c2d13-7060-459d-b73f-402796ce971a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zQl2lMSgvAYJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from typing import Any\n",
        "from typing import Dict\n",
        "\n",
        "import gymnasium\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_TRIALS = 100\n",
        "N_STARTUP_TRIALS = 5\n",
        "N_EVALUATIONS = 2\n",
        "N_TIMESTEPS = int(2e4)\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "N_EVAL_EPISODES = 3\n",
        "\n",
        "ENV_ID = \"CartPole-v1\"\n",
        "\n",
        "DEFAULT_HYPERPARAMS = {\n",
        "    \"policy\": \"MlpPolicy\",\n",
        "    \"env\": ENV_ID,\n",
        "}\n"
      ],
      "metadata": {
        "id": "G-wrNAEyvbIr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    \"\"\"Sampler for A2C hyperparameters.\"\"\"\n",
        "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "    gae_lambda = 1.0 - trial.suggest_float(\"gae_lambda\", 0.001, 0.2, log=True)\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
        "    ortho_init = trial.suggest_categorical(\"ortho_init\", [False, True])\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\"])\n",
        "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
        "\n",
        "    # Display true values.\n",
        "    trial.set_user_attr(\"gamma_\", gamma)\n",
        "    trial.set_user_attr(\"gae_lambda_\", gae_lambda)\n",
        "    trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "    net_arch = [\n",
        "        {\"pi\": [64], \"vf\": [64]} if net_arch == \"tiny\" else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "    ]\n",
        "\n",
        "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "    return {\n",
        "        \"n_steps\": n_steps,\n",
        "        \"gamma\": gamma,\n",
        "        \"gae_lambda\": gae_lambda,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"ent_coef\": ent_coef,\n",
        "        \"max_grad_norm\": max_grad_norm,\n",
        "        \"policy_kwargs\": {\n",
        "            \"net_arch\": net_arch,\n",
        "            \"activation_fn\": activation_fn,\n",
        "            \"ortho_init\": ortho_init,\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fG8IdzE9veak"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrialEvalCallback(EvalCallback):\n",
        "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gymnasium.Env,\n",
        "        trial: optuna.Trial,\n",
        "        n_eval_episodes: int = 5,\n",
        "        eval_freq: int = 10000,\n",
        "        deterministic: bool = True,\n",
        "        verbose: int = 0,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            eval_env=eval_env,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            eval_freq=eval_freq,\n",
        "            deterministic=deterministic,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "        self.trial = trial\n",
        "        self.eval_idx = 0\n",
        "        self.is_pruned = False\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            super()._on_step()\n",
        "            self.eval_idx += 1\n",
        "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "            # Prune trial if need.\n",
        "            if self.trial.should_prune():\n",
        "                self.is_pruned = True\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pZnsM-cdvhwI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
        "    # Sample hyperparameters.\n",
        "    kwargs.update(sample_a2c_params(trial))\n",
        "    # Create the RL model.\n",
        "    model = A2C(**kwargs)\n",
        "    # Create env used for evaluation.\n",
        "    eval_env = Monitor(gymnasium.make(ENV_ID))\n",
        "    # Create the callback that will periodically evaluate and report the performance.\n",
        "    eval_callback = TrialEvalCallback(\n",
        "        eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=EVAL_FREQ, deterministic=True\n",
        "    )\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
        "    except AssertionError as e:\n",
        "        # Sometimes, random hyperparams can generate NaN.\n",
        "        print(e)\n",
        "        nan_encountered = True\n",
        "    finally:\n",
        "        # Free memory.\n",
        "        model.env.close()\n",
        "        eval_env.close()\n",
        "\n",
        "    # Tell the optimizer that the trial failed.\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    if eval_callback.is_pruned:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return eval_callback.last_mean_reward\n"
      ],
      "metadata": {
        "id": "uOWn3-u8vl7I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set pytorch num threads to 1 for faster training.\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used.\n",
        "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3)\n",
        "\n",
        "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrUb7hJLvu8H",
        "outputId": "ef3b1bea-2795-4029-b8bf-0212d6ff1591"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-27 13:26:40,739] A new study created in memory with name: no-name-61ed41f8-1f38-4d83-a304-36d7750773a3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, timeout=600)\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsyMZyHuvAxV",
        "outputId": "416230b4-cf3f-4b91-b5d3-ef8b7c0ae6e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:484: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "[I 2024-02-27 13:27:28,502] Trial 0 finished with value: 56.333333333333336 and parameters: {'gamma': 0.004888382290198255, 'max_grad_norm': 1.4746470741386997, 'gae_lambda': 0.02594818986049887, 'exponent_n_steps': 5, 'lr': 0.00015016616707892838, 'ent_coef': 3.0061353975618693e-05, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 56.333333333333336.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:484: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "[I 2024-02-27 13:28:00,986] Trial 1 finished with value: 332.0 and parameters: {'gamma': 0.059612056929503575, 'max_grad_norm': 0.9402208061172472, 'gae_lambda': 0.13961215239230276, 'exponent_n_steps': 4, 'lr': 0.001472146344265128, 'ent_coef': 7.532601397617466e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: 332.0.\n",
            "[I 2024-02-27 13:28:29,520] Trial 2 finished with value: 9.333333333333334 and parameters: {'gamma': 0.02237570457006807, 'max_grad_norm': 0.4110804013223828, 'gae_lambda': 0.1322926432889405, 'exponent_n_steps': 9, 'lr': 0.16770386136047644, 'ent_coef': 1.5480799640816e-05, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 1 with value: 332.0.\n",
            "[I 2024-02-27 13:28:59,362] Trial 3 finished with value: 500.0 and parameters: {'gamma': 0.016215251076663426, 'max_grad_norm': 2.9980383614426547, 'gae_lambda': 0.05234680936314967, 'exponent_n_steps': 9, 'lr': 0.004833323714818564, 'ent_coef': 3.0921592680438754e-07, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:29:34,747] Trial 4 finished with value: 59.666666666666664 and parameters: {'gamma': 0.00013297651633294107, 'max_grad_norm': 0.34256437324548394, 'gae_lambda': 0.17132050591657066, 'exponent_n_steps': 3, 'lr': 0.0013501383466277572, 'ent_coef': 5.1216619457664755e-05, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:29:48,334] Trial 5 pruned. \n",
            "[I 2024-02-27 13:30:02,245] Trial 6 pruned. \n",
            "[I 2024-02-27 13:30:16,585] Trial 7 pruned. \n",
            "[I 2024-02-27 13:30:45,063] Trial 8 finished with value: 297.6666666666667 and parameters: {'gamma': 0.06841365457802857, 'max_grad_norm': 2.473416436195906, 'gae_lambda': 0.03444969481441391, 'exponent_n_steps': 6, 'lr': 0.018941256545698767, 'ent_coef': 7.516981019159801e-07, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:30:58,674] Trial 9 pruned. \n",
            "[I 2024-02-27 13:31:26,606] Trial 10 finished with value: 135.33333333333334 and parameters: {'gamma': 0.0013745826040601247, 'max_grad_norm': 2.8840325288600117, 'gae_lambda': 0.049128076223711584, 'exponent_n_steps': 8, 'lr': 0.02248911332869599, 'ent_coef': 0.0008185598580020432, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:32:03,278] Trial 11 finished with value: 295.3333333333333 and parameters: {'gamma': 0.08189812294207709, 'max_grad_norm': 0.9033346250177556, 'gae_lambda': 0.07895553179872243, 'exponent_n_steps': 3, 'lr': 0.0012505673601937782, 'ent_coef': 3.349318777146845e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:32:17,570] Trial 12 pruned. \n",
            "[I 2024-02-27 13:32:32,947] Trial 13 pruned. \n",
            "[I 2024-02-27 13:33:03,447] Trial 14 finished with value: 474.0 and parameters: {'gamma': 0.010005671495008514, 'max_grad_norm': 1.7463490802048791, 'gae_lambda': 0.0167073493538797, 'exponent_n_steps': 6, 'lr': 0.005417558986145956, 'ent_coef': 1.45320715170442e-07, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:33:17,303] Trial 15 pruned. \n",
            "[I 2024-02-27 13:33:47,277] Trial 16 pruned. \n",
            "[I 2024-02-27 13:34:01,473] Trial 17 pruned. \n",
            "[I 2024-02-27 13:34:15,423] Trial 18 pruned. \n",
            "[I 2024-02-27 13:34:45,101] Trial 19 finished with value: 500.0 and parameters: {'gamma': 0.00913656845900365, 'max_grad_norm': 1.4814072124259257, 'gae_lambda': 0.023947275878582388, 'exponent_n_steps': 9, 'lr': 0.0071709730600546745, 'ent_coef': 0.0003093272248628681, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:34:58,759] Trial 20 pruned. \n",
            "[I 2024-02-27 13:35:28,793] Trial 21 finished with value: 145.66666666666666 and parameters: {'gamma': 0.009871495115214126, 'max_grad_norm': 1.6337305923338854, 'gae_lambda': 0.019378555565618807, 'exponent_n_steps': 7, 'lr': 0.006880274875373013, 'ent_coef': 0.0007379121432184157, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:35:56,986] Trial 22 pruned. \n",
            "[I 2024-02-27 13:36:10,870] Trial 23 pruned. \n",
            "[I 2024-02-27 13:36:24,566] Trial 24 pruned. \n",
            "[I 2024-02-27 13:36:55,097] Trial 25 finished with value: 285.0 and parameters: {'gamma': 0.0020187895337951973, 'max_grad_norm': 1.3411447664754221, 'gae_lambda': 0.024772995186242666, 'exponent_n_steps': 6, 'lr': 0.002315558521901341, 'ent_coef': 0.00011612523582615985, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n",
            "[I 2024-02-27 13:37:27,227] Trial 26 finished with value: 411.0 and parameters: {'gamma': 0.033526314367689346, 'max_grad_norm': 1.1091061534437348, 'gae_lambda': 0.01183429041129924, 'exponent_n_steps': 5, 'lr': 0.0005538662034120951, 'ent_coef': 2.635987462731618e-06, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 3 with value: 500.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3IoD8qTvxzD",
        "outputId": "75a719af-2a19-4523-ee44-b9a9d075a1ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials:  27\n",
            "Best trial:\n",
            "  Value:  500.0\n",
            "  Params: \n",
            "    gamma: 0.016215251076663426\n",
            "    max_grad_norm: 2.9980383614426547\n",
            "    gae_lambda: 0.05234680936314967\n",
            "    exponent_n_steps: 9\n",
            "    lr: 0.004833323714818564\n",
            "    ent_coef: 3.0921592680438754e-07\n",
            "    ortho_init: False\n",
            "    net_arch: small\n",
            "    activation_fn: tanh\n",
            "  User attrs:\n",
            "    gamma_: 0.9837847489233366\n",
            "    gae_lambda_: 0.9476531906368504\n",
            "    n_steps: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}